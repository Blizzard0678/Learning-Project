# Learning-Project
Hand Gesture Control for YouTube

Hands-Free Video Playback Control Using Computer Vision

This project introduces an innovative, vision-based system that allows users to control YouTube videos using hand gestures. By combining hand tracking, gesture recognition, and web automation, the system enables intuitive actions such as play, pause, volume control, and more â€“ all without touching the keyboard or mouse.

ğŸ“Œ Features

âœ‹ Real-time hand tracking using MediaPipe

ğŸ¤– Gesture recognition with customizable gesture mappings

â–¶ï¸ YouTube video control using PyAutoGUI / JavaScript injection

ğŸ”Š Volume and playback control (play, pause, next, previous, volume up/down)

âš¡ Low-latency, real-time processing

ğŸ“º Works with any YouTube video in any browser

ğŸ’» Cross-platform (Windows / macOS / Linux)

ğŸ§° Tech Stack
Component	Technology
Hand Tracking	MediaPipe Hands
Gesture Recognition	Python + Custom Rule-Based Logic
Web Control	PyAutoGUI / Selenium / JavaScript
Computer Vision	OpenCV
Programming Language	Python 3.x
ğŸ“¸ How It Works

The webcam captures real-time video frames.

The system processes each frame using MediaPipe to detect hands and landmarks.

Custom logic identifies specific gestures (e.g., open palm, closed fist, swipe).

Recognized gestures trigger actions on the YouTube player (Pause, Play, Volume, etc.).

ğŸ–¼ï¸ Gesture Mapping (Example)
Gesture	Action
âœ‹ Open Palm	Pause / Play
ğŸ‘Š Fist	Mute / Unmute
ğŸ‘‰ Index Finger Up	Increase Volume
âœŒï¸ Two Fingers	Decrease Volume
ğŸ‘‰ Swipe Right	Next Video
ğŸ‘‰ Swipe Left	Previous Video

You can modify gesture mappings in gesture_config.py.
